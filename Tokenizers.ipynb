{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenizers.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/payasvi/payasvi/blob/master/Tokenizers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6eZMypIO01i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8d077549-f709-4f7d-c268-e6565b5529f0"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import pandas as pd\n",
        "import urllib, json\n",
        "df=pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Office_Products_5.json.gz\",lines=True)\n",
        "df=df.head()\n",
        "print(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "       reviewerID        asin  ... unixReviewTime   reviewTime\n",
            "0  A32T2H8150OJLU  B00000JBLH  ...     1094169600   09 3, 2004\n",
            "1  A3MAFS04ZABRGO  B00000JBLH  ...     1197676800  12 15, 2007\n",
            "2  A1F1A0QQP2XVH5  B00000JBLH  ...     1293840000   01 1, 2011\n",
            "3   A49R5DBXXQDE5  B00000JBLH  ...     1145404800  04 19, 2006\n",
            "4  A2XRMQA6PJ5ZJ8  B00000JBLH  ...     1375574400   08 4, 2013\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_RdFGqjPX7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "92f3489a-2102-4d27-f8d3-b272e98cf1b4"
      },
      "source": [
        "def nltk_token(sentence):\n",
        "  token=dict()\n",
        "  token[\"Tokens\"] = word_tokenize(sentence)\n",
        "  return token\n",
        "\n",
        "df['reviewText_tokens']= df['reviewText'].apply(nltk_token)\n",
        "print(df[\"reviewText_tokens\"])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Tokens': ['I', 'bought', 'my', 'first', 'HP1...\n",
            "1    {'Tokens': ['WHY', 'THIS', 'BELATED', 'REVIEW'...\n",
            "2    {'Tokens': ['I', 'have', 'an', 'HP', '48GX', '...\n",
            "3    {'Tokens': ['I', ''ve', 'started', 'doing', 'm...\n",
            "4    {'Tokens': ['For', 'simple', 'calculations', '...\n",
            "Name: reviewText_tokens, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uY-J6qwcRZcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a6370fe1-64ee-4f4d-8653-4768fc1d6c69"
      },
      "source": [
        "from nltk.tokenize import MWETokenizer\n",
        "tokenize = MWETokenizer()\n",
        "\n",
        "def mwe_token(sentence):\n",
        "  Mwe=dict()\n",
        "  Mwe[\"MWE_tokens\"]=tokenize.tokenize(sentence)\n",
        "  return Mwe\n",
        "\n",
        "df['reviewText_mweTokens']= df['reviewText'].apply(mwe_token)\n",
        "print(df[\"reviewText_mweTokens\"])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'MWE_tokens': ['I', ' ', 'b', 'o', 'u', 'g', ...\n",
            "1    {'MWE_tokens': ['W', 'H', 'Y', ' ', 'T', 'H', ...\n",
            "2    {'MWE_tokens': ['I', ' ', 'h', 'a', 'v', 'e', ...\n",
            "3    {'MWE_tokens': ['I', ''', 'v', 'e', ' ', 's', ...\n",
            "4    {'MWE_tokens': ['F', 'o', 'r', ' ', 's', 'i', ...\n",
            "Name: reviewText_mweTokens, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BRh8wt1Qp1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b1d85b93-4118-45dc-cc39-c3a769a00182"
      },
      "source": [
        "def nltk_postag(sentence):\n",
        "  pos=dict()\n",
        "  pos[\"Position_Tags\"]=nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
        "  return pos\n",
        "\n",
        "df['reviewText_postntag']= df['reviewText'].apply(nltk_postag)\n",
        "print(df[\"reviewText_postntag\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'Position_Tags': [('I', 'PRP'), ('bought', 'V...\n",
            "1    {'Position_Tags': [('WHY', 'WRB'), ('THIS', 'N...\n",
            "2    {'Position_Tags': [('I', 'PRP'), ('have', 'VBP...\n",
            "3    {'Position_Tags': [('I', 'PRP'), (''ve', 'VBP'...\n",
            "4    {'Position_Tags': [('For', 'IN'), ('simple', '...\n",
            "Name: reviewText_postntag, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCVTWbiyR0Dr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "720fd79b-827b-41aa-edf8-3a0c3b0b8b1f"
      },
      "source": [
        "def nltk_adjectives(sentence):\n",
        "  adj=dict()\n",
        "  adj[\"adjectives\"] = [token for token, pos in nltk.pos_tag(word_tokenize(sentence)) if pos.startswith('J')]\n",
        "  return adj\n",
        "\n",
        "df['reviewText_adjectives']= df['reviewText'].apply(nltk_adjectives)\n",
        "print(df[\"reviewText_adjectives\"])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    {'adjectives': ['first', 'difficult', 'many', ...\n",
            "1    {'adjectives': ['old', 'satisfied', 'ower', 'f...\n",
            "2    {'adjectives': ['more', 'more', 'old', 'flawle...\n",
            "3    {'adjectives': ['more', 'good', 'available', '...\n",
            "4    {'adjectives': ['simple', 'best', 'financial',...\n",
            "Name: reviewText_adjectives, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}